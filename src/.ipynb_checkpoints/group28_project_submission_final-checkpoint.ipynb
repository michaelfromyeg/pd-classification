{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Parkinson's Disease Classification with KNN</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<subtitle><center>by Group 28 (Michael DeMarco, Philip Zhang, Chris Cai, Yuichi Ito)</center></subtitle>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"praat.png\" alt=\"Praat screenshot\" width=\"400\"/>\n",
    "\n",
    "<center><b>Figure 1</b> A screengrab from Praat, the acoustic analysis software used in collecting the data set</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This project aims to classify whether or not a given patient has Parkinson's disease based on various variables derived from their speech sounds. We used a KNN classification algorithm with six predictors to create a model with an accuracy of 80%. We concluded it's accuracy is satisfactory for the scope of DSCI 100, working with the tools we had, but not accurate enough for commercial use. We discussed how this study may be extended to other degenerative diseases. Finally, we elaborated on how one would make such a model usable by the public by providing a website frontend for collecting new data points to test.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Introduction\n",
    "    - Background\n",
    "    - Question\n",
    "    - Data set\n",
    "- Methods\n",
    "    - Data wrangling and pre-processing\n",
    "    - Conducting the Classification Analysis\n",
    "    - Predictors\n",
    "    - Visualizing the Results\n",
    "- Exploration\n",
    "    - Preliminary exploratory data analysis in R\n",
    "    - Reading in the data\n",
    "    - Wrangling\n",
    "    - Creating the training and testing sets\n",
    "    - Training set in detail\n",
    "    - Predictors in detail\n",
    "- Hypothesis\n",
    "    - Expected Outcomes\n",
    "- Results\n",
    "    - Classification & Visualization\n",
    "- Discussion\n",
    "    - Summary\n",
    "    - Impact\n",
    "    - Next Steps\n",
    "- References\n",
    "    - Works Cited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "### Background\n",
    "Parkinson’s disease (PD) is a degenerative disorder of the central nervous system (CNS) which severely impacts motor control. Parkinson’s has neither a cure nor a known cause. Speech, however, is widely known to play a significant role in the detection of PD. According to Sakar<sup>1</sup> , vocal disorder exists in 90% of patients at an early stage.\n",
    "\n",
    "[1]  Here's the link to the original [data set](http://archive.ics.uci.edu/ml/datasets/Parkinson%27s+Disease+Classification), and corresponding [paper](https://www.sciencedirect.com/science/article/abs/pii/S1568494618305799?via%3Dihub). Note that the paper used the data set with a similar goal but with very different predictor variables than the ones we select here.\n",
    "\n",
    "### Question\n",
    "To what extent can we use elements of speech sounds to predict whether or not a patient has Parkinson’s disease?\n",
    "\n",
    "### Data set\n",
    "Our data set is from [UCI’s Machine Learning repository](http://archive.ics.uci.edu/ml/datasets/Parkinson%27s+Disease+Classification). This data set contains numerous variables derived from speech sounds gathered by Sakar using the [Praat](http://www.fon.hum.uva.nl/praat/) acoustic analysis software. Each participant in the study was asked to repeat their pronunciations of the /a/ phoneme three times; each entry is thus associated with an ID parameter ranging from 0 to 251.  We chose to focus on the following six predictor parameters:\n",
    "\n",
    "\n",
    "| Speech Sound Component               | Variable Name in Data Set | Description                                                      |\n",
    "|------------------------------------------|---------------------------|------------------------------------------------------------------|\n",
    "| Pitch Period Entropy (PPE)⁠               | PPE                       | measures the impaired control of someone’s pitch                 |\n",
    "| Detrended Fluctuation Analysis (DFA)⁠     | DFA                       | a measure of the ‘noisiness’ of speech waves                     |\n",
    "| Recurrence Period Density Entropy (RPDE)⁠ | RPDE                       | repetitiveness of speech waves                                   |\n",
    "| Jitter                                   | locPctJitter                       | a measure of frequency instability                               |\n",
    "| Shimmer                                  | locShimmer                       | a measure of amplitude instability                               |\n",
    "| Fundamental Frequency                    | meanPeriodPulses                       | someone’s pitch (calculated from the inverse of the mean period)⁠ |\n",
    "\n",
    "<center><b>Figure 2</b> Table describing each of the predictor's used in the original analysis</center>\n",
    "\n",
    "There’s a lot of complicated mathematics associated with each of these parameters (including Fourier transforms, dense equations, etc.) so the interested reader is encouraged to reference Sakar directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Methods\n",
    "### Predictors\n",
    "Many researchers have attempted to use speech signal processing for Parkinson’s disease classification. Based on Sakar and other widely supported literature, the predictors identified above are the most popular speech features used in PD studies and should prove effective. They are also all related to motor control, which is what the early stages of Parkinson’s directly impacts.\n",
    "\n",
    "### Data wrangling and pre-processing\n",
    "Each participant’s data (i.e., their pronunciation of /a/) was collected three times; to analyze this data set, each of these three observations was merged by taking the mean of each of our predictor variables in question.\n",
    "\n",
    "The data was not completely tidy, but the columns that we used were, so the untidy columns were neglected. Next, to be able to conduct classification, our predictor variables were standardized and centered. Each of our variables had a unique distribution; PPE, DFA, and RPDE were on a scale of 0 to 1 and the pitch variable was on an order of magnitude to 10<sup>-3</sup>, for example, so the entire data set was scaled so that we did not have to worry about each variable’s individual distribution.\n",
    "\n",
    "### Conducting the Classification Analysis\n",
    "Since our question is a binary classification problem, we used the K-nearest neighbours classification algorithm (KNN). We optimized our choice of k using cross-validation on our training set, and then used the optimal choice of k to create our final model. We then determined its accuracy using the test set.\n",
    "\n",
    "### Visualizing the Results\n",
    "To visualize the effectiveness of our KNN model, we were not able to draw a scatter plot directly, as we worked with more than 2-dimensions. We had a line plot showing the trend of increasing values of k on the accuracy of our model for many folds to assist in determining which k we should use for our final model. Then, we created a bar plot to show the number of correct predictions, false positives, and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"example-knn.png\" alt=\"Example KNN plot\" width=\"400\"/>\n",
    "\n",
    "<center><b>Figure 3</b> An example knn visualization with only two predictors. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Exploration\n",
    "### Exploratory data analysis\n",
    "\n",
    "We conducted a preliminary exploration of the data, to getter a better sense of what we were working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall packages (if needed)\n",
    "# install.packages(\"tidyverse\")\n",
    "# install.packages(\"caret\")\n",
    "# install.packages(\"repr\")\n",
    "# install.packages(\"GGally\")\n",
    "# install.packages(\"formula.tools\")\n",
    "\n",
    "# Fix for strange error message\n",
    "# install.packages(\"e1071\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'library' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-71c8339c57fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load in the necessary libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGGally\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtidyverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'library' is not defined"
     ]
    }
   ],
   "source": [
    "# Load in the necessary libraries\n",
    "library(caret)\n",
    "library(repr)\n",
    "library(GGally)\n",
    "library(tidyverse)\n",
    "library(formula.tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all of the following results reproducible, use this value across the analysis\n",
    "set.seed(28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "To begin, we read in the data from the UCI repository. We did not read it directly from UCI's URL, as it contained a zip, and trying to deal with that in R is tedious. Rather, we uploaded the file to Google Drive and we accessed it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the dataset from the web into R; the Drive URL is self-made\n",
    "pd_data <- read_csv(\"https://drive.google.com/uc?export=download&id=1p9JuoTRM_-t56x7gptZU2TRNue8IHFHc\", skip = 1)\n",
    "\n",
    "#narrows down the dataset to the variables that we will use\n",
    "baseline_data <- pd_data %>%\n",
    "                select(id:meanHarmToNoiseHarmonicity, class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(baseline_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 4</b> A slice of the basline data loaded from the UCI repository</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling\n",
    "\n",
    "As was mentioned in the methods section, each participant was represented three times (e.g., see three rows with `id == 0` above). We merged these by taking the mean of each of the predictor columns, after grouping by `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages the values of each subject's three trials so that each subject is represented by one row\n",
    "\n",
    "project_data <- baseline_data %>%\n",
    "                group_by(id) %>%\n",
    "                summarize(PPE = mean(PPE),\n",
    "                     DFA = mean(DFA),\n",
    "                     RPDE = mean(RPDE),\n",
    "                     meanPeriodPulses = mean(meanPeriodPulses),\n",
    "                     locPctJitter = mean(locPctJitter),\n",
    "                     locShimmer = mean(locShimmer),\n",
    "                     # meanAutoCorrHarmonicity = mean(meanAutoCorrHarmonicity),--legacy from project proposal\n",
    "                     class = mean(class)) %>%\n",
    "                     mutate(class = as.factor(class)) %>%\n",
    "                     mutate(has_pd = (class == 1))\n",
    "head(project_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 5</b> A table containing the tidied data and only relevant columns remaining</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training and testing sets\n",
    "Below we created the training and test sets using `createDataPartition()` from the `caret` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines which percentage of rows will be used in the training set and testing set (75%/25% split)\n",
    "set.seed(28)\n",
    "\n",
    "training_rows <- project_data %>%\n",
    "                select(has_pd) %>%\n",
    "                unlist() %>%\n",
    "                createDataPartition(p = 0.75, list = FALSE)\n",
    "\n",
    "# Splits the dataset into a training set and testing set\n",
    "training_set <- project_data %>% slice(training_rows)\n",
    "testing_set <- project_data %>% slice(-training_rows)\n",
    "\n",
    "head(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 6</b> A slice of our training set data, after splitting our data into two separate sets </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the data wrangling section of \"Methods,\" we eventually scaled our data. Scaling and other pre-processing was done in the analysis section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set in detail\n",
    "\n",
    "Here we looked at the testing set in more detail, exploring the balance and spread of our selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reports the number of counts per class\n",
    "class_counts <- training_set %>%\n",
    "                    group_by(has_pd) %>%\n",
    "                    summarize(n = n())\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 7</b> A table displaying the balance in our training set </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=4,repr.plot.height=4)\n",
    "\n",
    "class_counts_plot <- ggplot(class_counts, aes(x = has_pd, y = n, fill = has_pd)) + \n",
    "                   geom_bar(stat=\"identity\") +\n",
    "                   labs(x = 'Has PD?', y = 'Number', fill = \"Has PD\") +\n",
    "                   ggtitle(\"Balance in PD Data Set\") +\n",
    "                   theme(text = element_text(size = 18), legend.position = \"none\")\n",
    "class_counts_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 8</b> Visualizing the balance in our training set using a bar chart </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had many more—almost three times as many—patients with PD than without in this data set. Therefore, we could conclude our training set was somewhat imbalanced (in fact, it was the same imbalance as the original data set thanks to `createDataPartition()` handling stratification for us); however, it was not severe enough to warrant use of `upScale()`. This limitation is further discussed at the end of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reports the means, maxes, and mins of each predictor variable used\n",
    "predictor_max <- training_set %>%\n",
    "                        select(PPE:locShimmer) %>%\n",
    "                        map_df(~ max(., na.rm  = TRUE))\n",
    "predictor_min <- training_set %>%\n",
    "                        select(PPE:locShimmer) %>%\n",
    "                        map_df(~ min(., na.rm  = TRUE))\n",
    "predictor_mean <- training_set %>%\n",
    "                        select(PPE:locShimmer) %>%\n",
    "                        map_df(~ mean(., na.rm  = TRUE))\n",
    "\n",
    "stats_merged <- rbind(predictor_max, predictor_min, predictor_mean)\n",
    "\n",
    "stat <- c('max','mean','min')\n",
    "\n",
    "stats_w_names <- data.frame(stat, stats_merged)\n",
    "\n",
    "predictor_stats <- gather(stats_w_names,\n",
    "                              key = variable,\n",
    "                              value = value,\n",
    "                              PPE:locShimmer)\n",
    "predictor_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 9</b> A table containing the mean, max, and min of each of our predictor variables </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizes and compares the distributions of each of the predictor variables\n",
    "plot_pairs <- training_set %>% \n",
    "              select(PPE:locShimmer) %>% \n",
    "              ggpairs(title = \"PD speech predictor variable correlations\")\n",
    "# plot_pairs\n",
    "plot_pairs_by_class <- training_set %>%\n",
    "                       ggpairs(.,\n",
    "                               legend = 9,\n",
    "                               columns = 2:8, \n",
    "                               mapping = ggplot2::aes(colour=has_pd), \n",
    "                               lower = list(continuous = wrap(\"smooth\", alpha = 0.3, size=0.1)),\n",
    "                               title = \"PD speech predictor variable correlations by class\") +\n",
    "                       theme(legend.position = \"bottom\")\n",
    "# plot_pairs_by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two plots were created using the `GGPairs` library. The first, without color, strictly provides detail about the distribution and correlation between each pair created from our six predictor variables. Three of our predictors, DFA, RPDE, and meanPeriodPulses take on a much wider range of values than PPE, jitter, and shimmer. Many of our variables exhibit somewhat positive correlations on the scatterplot, though some have an entirely fuzzy distribution. For example, compare the plots in the PPE column to those in the RPDE column. This likely comes as a result of the spread of the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10,repr.plot.height=10, repr.plot.pointsize=20)\n",
    "\n",
    "plot_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 10</b> A pairwise visualization exploring the relationships between our predictor variables </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this understanding, we used a second plot, grouped and colored by `has_pd`, to assist in anticipating what the impact of these predictors would be. We noted that for every individual distribution, there is a marked difference between the red and blue groupings, which boded well for our analysis. On average, the healthy patients (i.e., `has_pd == FALSE`) fell on the lower end of the spectrum for our predictors, apart from PPE, where healthy patients exhibited higher values on average. Though we weren’t able to visualize our final model directly (as it was in six dimensions), we predicted from these plots that the new patients which fell on the \"lower end\" for most of these variables would be healthy. This also made intuitive sense; Parkinson’s is a degenerative disease for the muscles, so unhealthy patients would likely experience more rapid change in various speech variables due to tremors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10,repr.plot.height=10, repr.plot.pointsize=20)\n",
    "\n",
    "plot_pairs_by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 11</b> Another visualization of the relationship between our predictors, now with their class distributions considered </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Hypothesis\n",
    "\n",
    "### Expected Outcomes\n",
    "From our analysis, we expected to find that the six variables of speech we identified could form an effective model for determining whether or not a patient has Parkinson’s. We anticipated our findings would allow us to make reasonable predictions of whether or not a new patient has PD given their speech data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Analysis\n",
    "### Classification & Visualization\n",
    "\n",
    "#### Using all predictors from proposal\n",
    "Below is our first attempt at constructing a classification model using all predictors from the proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data set (pre-processing)\n",
    "scale_transformer <- preProcess(training_set, method = c(\"center\", \"scale\")) \n",
    "training_set <- predict(scale_transformer, training_set)\n",
    "testing_set <- predict(scale_transformer, testing_set)\n",
    "# head(training_set)\n",
    "# head(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train <- training_set %>% \n",
    "  select(-class, -has_pd) %>% \n",
    "  data.frame()\n",
    "X_test <- testing_set %>% \n",
    "  select(-class, -has_pd) %>% \n",
    "  data.frame()\n",
    "Y_train <- training_set %>% \n",
    "  select(class) %>% \n",
    "  unlist()\n",
    "Y_test <- testing_set %>% \n",
    "  select(class) %>% \n",
    "  unlist()\n",
    "# head(X_train)\n",
    "# head(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_control <- trainControl(method=\"cv\", number = 10)\n",
    "k <- data.frame(k = seq(from = 1, to = 51, by = 2))\n",
    "knn_model_cv_10fold <- train(x = X_train, y = Y_train, method = \"knn\", tuneGrid = k, trControl = train_control)\n",
    "# knn_model_cv_10fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies <- knn_model_cv_10fold$results\n",
    "head(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 12 </b> A table containing the accuracy values for our first few values of k </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height = 5, repr.plot.width = 5)\n",
    "\n",
    "accuracy_vs_k <- ggplot(accuracies, aes(x = k, y = Accuracy)) +\n",
    "  geom_point() +\n",
    "  geom_line() + \n",
    "  ggtitle(\"Graphing Accuracy Against K\") +\n",
    "  labs(subtitle = \"Initial attempt—all predictors used\")\n",
    "accuracy_vs_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 13 </b> A plot of accuracies of various k-values for a 10-fold cross-validation </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k <- accuracies %>%\n",
    "    arrange(desc(Accuracy)) %>%\n",
    "    head(n = 1) %>%\n",
    "    select(k)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 14 </b> A table containing the optimal choice of k </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a choice of 5 here yields the high accuracy value. After approximately a k value of 40, our accuracy plateaus at just above 0.75. We will now retrain our model using this choice of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = data.frame(k = 5)\n",
    "model_knn <- train(x = X_train, y = Y_train, method = \"knn\", tuneGrid = k)\n",
    "# model_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_predicted <- predict(object = model_knn, X_test)\n",
    "# head(Y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quality <- confusionMatrix(data = Y_test_predicted, reference = Y_test)\n",
    "model_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 15 </b> Our final model statistics for our data set with all predictors </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final model had an accuracy of 79.4%, which is pretty good! Give our model is in six dimensions, there is no simple visualization for it. However, we can visualize whether or not our model had more false positives or false negatives, and which it was better are predicting: sick or healthy. The confusion matrix gives us all of these values in a 2x2 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "matrix_table <- as.data.frame(model_quality$table) %>%\n",
    "    mutate(isCorrect = (Prediction == Reference))\n",
    "# matrix_table\n",
    "\n",
    "matrix_plot <- ggplot(matrix_table, aes(fill = isCorrect, x = Reference, y = Freq)) +\n",
    "  geom_bar(position=\"stack\", stat=\"identity\", width = 0.7) + \n",
    "  labs(title = \"Confusion Matrix Bar Chart\", y = \"Frequency\", x = \"Has PD?\") +\n",
    "  scale_fill_discrete(name=\"Correction Prediction?\")\n",
    "matrix_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Figure 16 </b> Visualizing our confusion matrix table; note that on the bottom if 'Has PD?' is 1, this means the patient does have Parkinson's. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted from the above bar chart that our model was fairly accurate at predicting whether or not a patient *did* have Parkinson's, but were very inaccurate when working with *healthy* patients. This was likely a result of our imbalanced training set, though we did still end up with an 80% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Discussion\n",
    "### Summary\n",
    "### Impact\n",
    "\n",
    "Being able to predict Parkinson’s accurately has significant impact alone; doctors often struggle to make accurate, timely predictions as Parkinson’s is a long-term degenerative disease. Additionally, there are no specific tests for determining whether or not someone has Parkinson’s. Currently a neurologist must use a combination of other factors like medical history, signs and symptoms, and a physical examination to make a prediction. Speech sounds could be another cheap, fast tool for a neurologist to employ to help them make a more accurate prediction.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "From this analysis, I could see us moving to three questions for further study:\n",
    "\n",
    "- Can different variables in speech sounds be used to predict other degenerative diseases that have a similar impact on movement? (e.g., Lou Gehrig's disease)\n",
    "- Can other parts of physiology be used as an indicator of whether or not someone has Parkinson’s disease? (e.g., gross or fine motor control)\n",
    "- What other parts of speech sounds could be used to predict Parkinson’s disease? (e.g., as the study suggests (e.g., Q-factor wavelet transform)\n",
    "\n",
    "Beyond these further questions, it would also be interesting to see the use of this model in a practical setting. For example, this model could be used by doctors in combination with the patient's other symptoms to make a more accurate prediction. In fact, [Google](https://www.nature.com/articles/s41586-019-1799-6) has a similar system for breast cancer screening currently under international review. Given countless electronic devices we interact with on a day-to-day basis possess a microphone, this could even be done without the doctor's help. The only catch would be the consumer-facing product would need to give ample warnings about a potential false-negative or false-positive, and would additionally need to be robust enough to collect the relevant variables from a speech sound, like Praat did in collecting the data set used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 References\n",
    "\n",
    "### Works Cited\n",
    "\n",
    "Sakar, C. O., Serbes, G., Gunduz, A., Tunc, H. C., Nizam, H., Sakar, B. E., Apaydin, H. (2019). A comparative analysis of speech signal processing algorithms for parkinson's disease classification and the use of the tunable Q-factor wavelet transform. Applied Soft Computing Journal, 74, 255. doi:10.1016/j.asoc.2018.10.022."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
